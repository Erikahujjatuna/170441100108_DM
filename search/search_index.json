{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BIODATA \u00b6 Nama : Erika Hujjatuna Annisak TTL : Sumenep, 18-02-2000 NIM : 170441100108 Universitas : Trunojoyo Madura Alamat : Jl.Wiraraja II patean utara","title":"Home"},{"location":"#biodata","text":"Nama : Erika Hujjatuna Annisak TTL : Sumenep, 18-02-2000 NIM : 170441100108 Universitas : Trunojoyo Madura Alamat : Jl.Wiraraja II patean utara","title":"BIODATA"},{"location":"DecisionTree/","text":"DECISION TREE (Pohon Keputusan) \u00b6 Python | Decision Tree Regression using sklearn \u00b6 \u200b Decision tree adalah alat pengambil keputusan yang menggunakan struktur pohon seperti flowchart. Dan merupakan alat yang digunakan untuk klasifikasi dan prediks, pohon keputusan merupakan diagram alur seperti struktur pohon, dimana setiap nod internal menunjukkan tes pada atribut, masing-masing cabang mewakili hasil tes, dan setiap node daun memegang label kelas. Kontruksi pada Decision Tree \u00b6 \u200b Sebuah pohon dapat \"dipelajari\" dengan memecah sumber set kedalam sub set berdasarkan tes nilai atribut. Proses ini diulang pada setiap subset yang berasal dalam cara rekursif yang disebut rekursif partisi. Rekursi selesai ketika subset semua di node memiliki nilai variable target yang sama, atau ketika membelah tidak lagi menambah nilai prediksi. Pembangunan klasifikasi pohon keputusan tidak memerlukan pengetahuan domain. Representasi Decision Tree \u00b6 \u200b Decision tree mengklasifikasikan instance dengan menyortir mereka menuruni pohon dari akar ke beberapa node daun, yang menyediakan klasifikasi instance. Sebuah instance diklasifikasi dengan beberapa tahapan : Klasifikasi pada simpul pohon Menguji atribut yang ditentukan Memindahkan cabang pohon sesuai dengan nilai dari atribut proses diulang untuk sub pohon yang berakar pada nod baru Konsep Decision Tree \u00b6 \u200b Decision tree digunakan untuk mengklasifikasi suatu sample data yang belum diketahui kelasnya, ke dalam kelas-kelas yang sudah ada. Jalur pegujian data adalah pertama melalui root node (simpul akar) dan terakhir adalah melalui leaf node (simpul daun) yang akan menyimpulkan prediksi kelas bagi data tersebut. Proses Algoritma Dalam Decision Tree \u00b6 Menghitung nilai Entropy total dataset Menghitung Entropy dan Gain pada setiap atribut Membuat table perhitungan pada Node Membuat Node dengan hasil Gain tertinggi dari table Mengulangi langkah 2-5 sehingga tidak ada node lagi. Entropy \u00b6 \u200b Adalah jumlah bit yang diperkirakan dibutuhkan untuk dapat mengekstrak suatu kelas (+ atau -) dari sejumlah data acak pada ruang sample. Untuk menghitung information gain, terlebih dahulu kita harus memahami suatu nilai entropy, entropy bisa digunakan sebagai suatu parameter untuk mengukur keberagaman dari suatu kumpulan sample data. jika kumpulan sample data semakin beragam, maka semakin besar pula nilai entropy. secara matematis, nilai entropy masing-masing instance dirumuskan sebagai berikut : Gain Ratio \u00b6 \u200b Gain merupakan reduksi yang diharapkan dalam entropy yang disebabkan oleh pengetahuan nilai atribut. Atribut dengan nilai gain terbesar dipilih sebagai tes atribut (simpul akar). Hal ini dapat digunakan untuk menentukan urutan atribut , dan urutan inilah yang nantinya akan membentuk pohon keputusan (decision tree). Contoh Kasus \u00b6 No Pelatih Kadang sendiri Latihan Stamina Mental Menag 1 Pengertian Ya Rutin Kuat PD Ya 2 Pengertian Ya Rutin Kuat Gerogi tidak 3 Pengertian Ya Rutin Lemah PD Ya 4 Pengertian Ya Jarang Lemah PD Ya 5 Pengertian Ya Tidak ada Lemah PD Tidak 6 Pengertian Tidak Rutin Kuat PD Ya 7 Pengertian Tidak Jarang Lemah Gerogi Tidak 8 Menekan Ya Rutin Lemah PD Ya 9 Menekan Tidak Rutin Lemah Gerogi Tidak 10 Menekan Ya Jarang Lemah Gerogi Tidak 11 Menekan Ya Rutin Kuath PD Ya 12 Menekan Tidak Rutin Kuat PD Ya Atribut : pelatih, kadang sendiri, latihan, stamina, mental kelas : menang = ya atau tidak jumlah data ada 12, terdiri dari : ya = 7, tidak = 5. Menghitung Entropy Total Dataset Menghitung Entropy dan gain tiap atribut Table perhitungan Node 1 dari gambar diatas dapat dilhat bahwa nilai gain tertinggi adalah pada attribut mental, maka mental yang akan menjadi node akar (root node). dalam atribut mental terdapat dua nilai yaitu \"PD\" dan \"Grogi\". karena atribut grogi sudah mengklasifikasikan kasus menjadi satu keputusan yaitu \"Tidak\", maka atribut ini tidak perlu melakukan penghitungan lebih lanjut, tetapi untuk atribut \"PD\" masih perlu dilakukan perhitungan lagi, karena masih terdapat nialai \"ya\" dan \"tidak\". Gambar decision tree Node 1 Berikut table data yang akan dianalisis lebih lanjut yang memiliki atribut = PD Menghitung Entropy total dari node 1.1: Menghitung entropy dan gain keseluruhan atribut node 1.1 selanjutnya menentukan nilai gain tertinggi, gain tertinggi adalah di fitur Latihan , sebesar 0.5435. maka latihan yang akan dijadikan node selanjutnya, karena pada node latihan semua atributnya sudah mengklasifikasi menjadi satu keputusan, maka tidak perlu melakukan perhitungan lebih lanjut. Dengan demikian decision tree akan tampak seperti berikut : Python | Decision Tree Regession using sklearn \u00b6 Step 1: # import numpy package for arrays and stuff import numpy as np # import matplotlib.pyplot for plotting our result import matplotlib.pyplot as plt # import pandas for importing csv files import pandas as pd Step 2: # import dataset # dataset = pd.read_csv('Data.csv') # alternatively open up .csv file to read data dataset = np.array( [['Asset Flip', 100, 1000], ['Text Based', 500, 3000], ['Visual Novel', 1500, 5000], ['2D Pixel Art', 3500, 8000], ['2D Vector Art', 5000, 6500], ['Strategy', 6000, 7000], ['First Person Shooter', 8000, 15000], ['Simulator', 9500, 20000], ['Racing', 12000, 21000], ['RPG', 14000, 25000], ['Sandbox', 15500, 27000], ['Open-World', 16500, 30000], ['MMOFPS', 25000, 52000], ['MMORPG', 30000, 80000] ]) # print the dataset print(dataset) Step 3: # select all rows by : and column 1 # by 1:2 representing features X = dataset[:, 1:2].astype(int) # print X print(X) Step 4: # select all rows by : and column 2 # by 2 to Y representing labels y = dataset[:, 2].astype(int) # print y print(y) Step 5: # import the regressor from sklearn.tree import DecisionTreeRegressor # create a regressor object regressor = DecisionTreeRegressor(random_state = 0) # fit the regressor with X and Y data regressor.fit(X, y) Step 6: # arange for creating a range of values # from min value of X to max value of X # with a difference of 0.01 between two # consecutive values X_grid = np.arange(min(X), max(X), 0.01) # reshape for reshaping the data into # a len(X_grid)*1 array, i.e. to make # a column out of the X_grid values X_grid = X_grid.reshape((len(X_grid), 1)) # scatter plot for original data plt.scatter(X, y, color = 'red') # plot predicted data plt.plot(X_grid, regressor.predict(X_grid), color = 'blue') # specify title plt.title('Profit to Production Cost (Decision Tree Regression)') # specify X axis label plt.xlabel('Production Cost') # specify Y axis label plt.ylabel('Profit') # show the plot plt.show() Step 7: # import export_graphviz from sklearn.tree import export_graphviz # export the decision tree to a tree.dot file # for visualizing the plot easily anywhere export_graphviz(regressor, out_file ='tree.dot', feature_names =['Production Cost']) Output","title":"Decision Tree"},{"location":"DecisionTree/#decision-tree-pohon-keputusan","text":"","title":"DECISION TREE (Pohon Keputusan)"},{"location":"DecisionTree/#python-decision-tree-regression-using-sklearn","text":"\u200b Decision tree adalah alat pengambil keputusan yang menggunakan struktur pohon seperti flowchart. Dan merupakan alat yang digunakan untuk klasifikasi dan prediks, pohon keputusan merupakan diagram alur seperti struktur pohon, dimana setiap nod internal menunjukkan tes pada atribut, masing-masing cabang mewakili hasil tes, dan setiap node daun memegang label kelas.","title":"Python | Decision Tree Regression using sklearn"},{"location":"DecisionTree/#kontruksi-pada-decision-tree","text":"\u200b Sebuah pohon dapat \"dipelajari\" dengan memecah sumber set kedalam sub set berdasarkan tes nilai atribut. Proses ini diulang pada setiap subset yang berasal dalam cara rekursif yang disebut rekursif partisi. Rekursi selesai ketika subset semua di node memiliki nilai variable target yang sama, atau ketika membelah tidak lagi menambah nilai prediksi. Pembangunan klasifikasi pohon keputusan tidak memerlukan pengetahuan domain.","title":"Kontruksi pada Decision Tree"},{"location":"DecisionTree/#representasi-decision-tree","text":"\u200b Decision tree mengklasifikasikan instance dengan menyortir mereka menuruni pohon dari akar ke beberapa node daun, yang menyediakan klasifikasi instance. Sebuah instance diklasifikasi dengan beberapa tahapan : Klasifikasi pada simpul pohon Menguji atribut yang ditentukan Memindahkan cabang pohon sesuai dengan nilai dari atribut proses diulang untuk sub pohon yang berakar pada nod baru","title":"Representasi Decision Tree"},{"location":"DecisionTree/#konsep-decision-tree","text":"\u200b Decision tree digunakan untuk mengklasifikasi suatu sample data yang belum diketahui kelasnya, ke dalam kelas-kelas yang sudah ada. Jalur pegujian data adalah pertama melalui root node (simpul akar) dan terakhir adalah melalui leaf node (simpul daun) yang akan menyimpulkan prediksi kelas bagi data tersebut.","title":"Konsep Decision Tree"},{"location":"DecisionTree/#proses-algoritma-dalam-decision-tree","text":"Menghitung nilai Entropy total dataset Menghitung Entropy dan Gain pada setiap atribut Membuat table perhitungan pada Node Membuat Node dengan hasil Gain tertinggi dari table Mengulangi langkah 2-5 sehingga tidak ada node lagi.","title":"Proses Algoritma Dalam Decision Tree"},{"location":"DecisionTree/#entropy","text":"\u200b Adalah jumlah bit yang diperkirakan dibutuhkan untuk dapat mengekstrak suatu kelas (+ atau -) dari sejumlah data acak pada ruang sample. Untuk menghitung information gain, terlebih dahulu kita harus memahami suatu nilai entropy, entropy bisa digunakan sebagai suatu parameter untuk mengukur keberagaman dari suatu kumpulan sample data. jika kumpulan sample data semakin beragam, maka semakin besar pula nilai entropy. secara matematis, nilai entropy masing-masing instance dirumuskan sebagai berikut :","title":"Entropy"},{"location":"DecisionTree/#gain-ratio","text":"\u200b Gain merupakan reduksi yang diharapkan dalam entropy yang disebabkan oleh pengetahuan nilai atribut. Atribut dengan nilai gain terbesar dipilih sebagai tes atribut (simpul akar). Hal ini dapat digunakan untuk menentukan urutan atribut , dan urutan inilah yang nantinya akan membentuk pohon keputusan (decision tree).","title":"Gain Ratio"},{"location":"DecisionTree/#contoh-kasus","text":"No Pelatih Kadang sendiri Latihan Stamina Mental Menag 1 Pengertian Ya Rutin Kuat PD Ya 2 Pengertian Ya Rutin Kuat Gerogi tidak 3 Pengertian Ya Rutin Lemah PD Ya 4 Pengertian Ya Jarang Lemah PD Ya 5 Pengertian Ya Tidak ada Lemah PD Tidak 6 Pengertian Tidak Rutin Kuat PD Ya 7 Pengertian Tidak Jarang Lemah Gerogi Tidak 8 Menekan Ya Rutin Lemah PD Ya 9 Menekan Tidak Rutin Lemah Gerogi Tidak 10 Menekan Ya Jarang Lemah Gerogi Tidak 11 Menekan Ya Rutin Kuath PD Ya 12 Menekan Tidak Rutin Kuat PD Ya Atribut : pelatih, kadang sendiri, latihan, stamina, mental kelas : menang = ya atau tidak jumlah data ada 12, terdiri dari : ya = 7, tidak = 5. Menghitung Entropy Total Dataset Menghitung Entropy dan gain tiap atribut Table perhitungan Node 1 dari gambar diatas dapat dilhat bahwa nilai gain tertinggi adalah pada attribut mental, maka mental yang akan menjadi node akar (root node). dalam atribut mental terdapat dua nilai yaitu \"PD\" dan \"Grogi\". karena atribut grogi sudah mengklasifikasikan kasus menjadi satu keputusan yaitu \"Tidak\", maka atribut ini tidak perlu melakukan penghitungan lebih lanjut, tetapi untuk atribut \"PD\" masih perlu dilakukan perhitungan lagi, karena masih terdapat nialai \"ya\" dan \"tidak\". Gambar decision tree Node 1 Berikut table data yang akan dianalisis lebih lanjut yang memiliki atribut = PD Menghitung Entropy total dari node 1.1: Menghitung entropy dan gain keseluruhan atribut node 1.1 selanjutnya menentukan nilai gain tertinggi, gain tertinggi adalah di fitur Latihan , sebesar 0.5435. maka latihan yang akan dijadikan node selanjutnya, karena pada node latihan semua atributnya sudah mengklasifikasi menjadi satu keputusan, maka tidak perlu melakukan perhitungan lebih lanjut. Dengan demikian decision tree akan tampak seperti berikut :","title":"Contoh Kasus"},{"location":"DecisionTree/#python-decision-tree-regession-using-sklearn","text":"Step 1: # import numpy package for arrays and stuff import numpy as np # import matplotlib.pyplot for plotting our result import matplotlib.pyplot as plt # import pandas for importing csv files import pandas as pd Step 2: # import dataset # dataset = pd.read_csv('Data.csv') # alternatively open up .csv file to read data dataset = np.array( [['Asset Flip', 100, 1000], ['Text Based', 500, 3000], ['Visual Novel', 1500, 5000], ['2D Pixel Art', 3500, 8000], ['2D Vector Art', 5000, 6500], ['Strategy', 6000, 7000], ['First Person Shooter', 8000, 15000], ['Simulator', 9500, 20000], ['Racing', 12000, 21000], ['RPG', 14000, 25000], ['Sandbox', 15500, 27000], ['Open-World', 16500, 30000], ['MMOFPS', 25000, 52000], ['MMORPG', 30000, 80000] ]) # print the dataset print(dataset) Step 3: # select all rows by : and column 1 # by 1:2 representing features X = dataset[:, 1:2].astype(int) # print X print(X) Step 4: # select all rows by : and column 2 # by 2 to Y representing labels y = dataset[:, 2].astype(int) # print y print(y) Step 5: # import the regressor from sklearn.tree import DecisionTreeRegressor # create a regressor object regressor = DecisionTreeRegressor(random_state = 0) # fit the regressor with X and Y data regressor.fit(X, y) Step 6: # arange for creating a range of values # from min value of X to max value of X # with a difference of 0.01 between two # consecutive values X_grid = np.arange(min(X), max(X), 0.01) # reshape for reshaping the data into # a len(X_grid)*1 array, i.e. to make # a column out of the X_grid values X_grid = X_grid.reshape((len(X_grid), 1)) # scatter plot for original data plt.scatter(X, y, color = 'red') # plot predicted data plt.plot(X_grid, regressor.predict(X_grid), color = 'blue') # specify title plt.title('Profit to Production Cost (Decision Tree Regression)') # specify X axis label plt.xlabel('Production Cost') # specify Y axis label plt.ylabel('Profit') # show the plot plt.show() Step 7: # import export_graphviz from sklearn.tree import export_graphviz # export the decision tree to a tree.dot file # for visualizing the plot easily anywhere export_graphviz(regressor, out_file ='tree.dot', feature_names =['Production Cost']) Output","title":"Python | Decision Tree Regession using sklearn"},{"location":"KNN/","text":"KNN (K-NEAREST NEIGHBOUR) \u00b6 Apa itu K-NN ?. \u00b6 \u200b K-NN (K-Nearest Neighbor) adalah suatu metode yang menggunakan algoritma, dimana hasil query instance yang baru diklasifikasikan berdasarkan mayoritas dari kategori pada KNN. tujuan dari algoritma adalah untuk mengklasifikasikan obyek baru berdasarkan atribut dan training sample. Algortitma K-NN \u00b6 \u200b Algoritma metode K-NN bekerja berdasarkan jarak terpendek dari query instance ke training sample. Training sample diproyeksi keruang berdimensi banyak, dimana masing-masing dimensi mempresentasikan fitur dari data. Ruang ini dibagi menjadi bagian-bagian berdasarkan klasifikasi training sample. Dekat atau jauhnya tetangga, biasanya dihitung berdasarkan Euclidean Distance. Langkah-langkah yang digunakan dalam metode K-Nearest Neighbor : Menentukan parameter \"K\" (jumlah tetangga paling dekat). Hitung kuadrat jarak euclidean pada masing-masing obyek terhadap data sample yang diberikan. Urutkan jarak tersebut dan tentukan tetangga yang terdekat berdasarkan jarak minimum ke-K . Tentukan kategori dari tetangga terdekat. Gunakan kategori mayoritas dari tetangga yang terdekat sebagai nilai prediksi dari data yang baru. Contoh perhitungan numerik \u00b6 \u200b \u200b Data diatas terdiri dari 2 atribut dengan skala kuantitatif X1 dan X2 serta 2 kelas yaitu Bagus dan Jelek. Jika terdapat data baru dengan nilai X1 = 3 dan X2 = 7. Kita gunakan algoritma K-NN untuk melakukan prediksi termasuk klasifikasi apa (Bagus atau Jelek) data baru ini ? Tentukan parameter K = jumlah banyaknya tetangga terdekat. Misalnya K= 3 . Hitung jarak antara data baru dan semua data yang ada di data training. Misal menggunakan square distance dari jarak antara data baru dengan semua data yang ada di data training. Urtkan jarak tersebut dan tentukan tetangga mana yang terdekat berdasarkan jarak minimum ke-K Periksa kelas dari tetangga terdekat Gunakan kategori mayoritas untuk memprediksi data yang baru. Kita mempunyai 2 kategori Bagus dan 1 kategori Jelek, karena 2>1 maka kita simpulkan bahwa kertas tissue baru yang memiliki X1 = 3 dan X2 = 7 termasuk dalam kategori Bagus. \u200b Untuk lebih mudah mengerjakan K-NN dengan jumlah data yang banyak kita bisa menggunakan kode-kode program seperti dibawah ini. Step 1: Import data yang yang dibutuhkan dan periksa fitur-fitur \u200b Import fungsi load_iris dari datasets module dan buat sebuah iris bunch object (bunch adalah scikit learn adalah tipe objec khusus untuk menyimpan dataset dan atributnya) #Import load_iris function dari datasets module from sklearn.datasets import load_iris #Create bunch object containing datasets and its attributes. iris = load_iris() type(iris) #Print the iris data iris.data #Print of 4 features (column names) print(iris.feature_names) #Integers representing the species: 0=setosa, 1=versicolor, 2=Virginica print(iris.target) #3 classes of target print(iris.target_names) print(type(iris.data)) print(type(iris.target)) #we have a total of 150 observation and 4 features print(iris.data.shape) #splitting the data into training and test sets (80:20) from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.2,random_state=4) #shape of train and test objects print(X_train.shape) print(X_test.shape) #shape of new y objects print(y_train.shape) print(y_test.shape) <b>Output</b> \u200b \u200b Dalam contoh kami, kami menciptakan sebuah instance (' KNN ') dari kelas ' Ktetangga Sclassifer ', dengan kata lain kami telah menciptakan sebuah objek yang disebut ' KNN ' yang tahu bagaimana melakukan KNN klasifikasi setelah kami menyediakan data. Parameter ' n_neighbors ' adalah parameter tuning/Hyper parameter (k). Semua parameter lainnya diatur ke nilai default. \u200b Metode ' Fit ' digunakan untuk melatih model pada data pelatihan (X_train, y_train) dan ' memprediksi ' metode untuk melakukan pengujian pada pengujian data (X_test). Memilih nilai optimal K sangat penting, jadi kami cocok dan menguji model untuk nilai yang berbeda untuk K (dari 1 sampai 45) menggunakan untuk loop dan merekam akurasi pengujian KNN dalam variabel (Skor). #Import the KNeighborsClassifier class from sclearn from sklearn.neighbors import KNeighborsClassifier clf=KNeighborsClassifier(n_neighbors=3).fit(X_train,y_train) from sklearn.metrics import accuracy_score print(\"accuracy is \") print(accuracy_score(y_test,clf.predict(X_test))) import matplotlib.pyplot as plt accuracy_values=[] #Try running from k=1 trhough 45 and record testing accuracy k_range = range(1,45) scores = {} scores_list = [] for k in k_range: knn = KNeighborsClassifier(n_neighbors=k) knn.fit(X_train,y_train) y_pred=knn.predict(X_test) scores[k] = accuracy_score(y_test,y_pred) scores_list.append(accuracy_score(y_test,y_pred)) import numpy as np accuracy_values=np.array(accuracy_values) #plot the relationship between k and the testing accuracy plt.plot(k_range,scores_list) plt.xlabel('Value of k for KNN') plt.ylabel('Testing Accuracy') Output \u200b Jadi untuk model terakhir, kita dapat memilih nilai yang optimal K antara 3 dan 19, antara 22 dan 25 yang merupakan nilai tertinggi dari testing accuracy. Mungkin sampai disini pembahasan dari Knowladge of KNN terima kasih.....","title":"K-NN"},{"location":"KNN/#knn-k-nearest-neighbour","text":"","title":"KNN (K-NEAREST NEIGHBOUR)"},{"location":"KNN/#apa-itu-k-nn","text":"\u200b K-NN (K-Nearest Neighbor) adalah suatu metode yang menggunakan algoritma, dimana hasil query instance yang baru diklasifikasikan berdasarkan mayoritas dari kategori pada KNN. tujuan dari algoritma adalah untuk mengklasifikasikan obyek baru berdasarkan atribut dan training sample.","title":"Apa itu K-NN ?."},{"location":"KNN/#algortitma-k-nn","text":"\u200b Algoritma metode K-NN bekerja berdasarkan jarak terpendek dari query instance ke training sample. Training sample diproyeksi keruang berdimensi banyak, dimana masing-masing dimensi mempresentasikan fitur dari data. Ruang ini dibagi menjadi bagian-bagian berdasarkan klasifikasi training sample. Dekat atau jauhnya tetangga, biasanya dihitung berdasarkan Euclidean Distance. Langkah-langkah yang digunakan dalam metode K-Nearest Neighbor : Menentukan parameter \"K\" (jumlah tetangga paling dekat). Hitung kuadrat jarak euclidean pada masing-masing obyek terhadap data sample yang diberikan. Urutkan jarak tersebut dan tentukan tetangga yang terdekat berdasarkan jarak minimum ke-K . Tentukan kategori dari tetangga terdekat. Gunakan kategori mayoritas dari tetangga yang terdekat sebagai nilai prediksi dari data yang baru.","title":"Algortitma K-NN"},{"location":"KNN/#contoh-perhitungan-numerik","text":"\u200b \u200b Data diatas terdiri dari 2 atribut dengan skala kuantitatif X1 dan X2 serta 2 kelas yaitu Bagus dan Jelek. Jika terdapat data baru dengan nilai X1 = 3 dan X2 = 7. Kita gunakan algoritma K-NN untuk melakukan prediksi termasuk klasifikasi apa (Bagus atau Jelek) data baru ini ? Tentukan parameter K = jumlah banyaknya tetangga terdekat. Misalnya K= 3 . Hitung jarak antara data baru dan semua data yang ada di data training. Misal menggunakan square distance dari jarak antara data baru dengan semua data yang ada di data training. Urtkan jarak tersebut dan tentukan tetangga mana yang terdekat berdasarkan jarak minimum ke-K Periksa kelas dari tetangga terdekat Gunakan kategori mayoritas untuk memprediksi data yang baru. Kita mempunyai 2 kategori Bagus dan 1 kategori Jelek, karena 2>1 maka kita simpulkan bahwa kertas tissue baru yang memiliki X1 = 3 dan X2 = 7 termasuk dalam kategori Bagus. \u200b Untuk lebih mudah mengerjakan K-NN dengan jumlah data yang banyak kita bisa menggunakan kode-kode program seperti dibawah ini. Step 1: Import data yang yang dibutuhkan dan periksa fitur-fitur \u200b Import fungsi load_iris dari datasets module dan buat sebuah iris bunch object (bunch adalah scikit learn adalah tipe objec khusus untuk menyimpan dataset dan atributnya) #Import load_iris function dari datasets module from sklearn.datasets import load_iris #Create bunch object containing datasets and its attributes. iris = load_iris() type(iris) #Print the iris data iris.data #Print of 4 features (column names) print(iris.feature_names) #Integers representing the species: 0=setosa, 1=versicolor, 2=Virginica print(iris.target) #3 classes of target print(iris.target_names) print(type(iris.data)) print(type(iris.target)) #we have a total of 150 observation and 4 features print(iris.data.shape) #splitting the data into training and test sets (80:20) from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.2,random_state=4) #shape of train and test objects print(X_train.shape) print(X_test.shape) #shape of new y objects print(y_train.shape) print(y_test.shape) <b>Output</b> \u200b \u200b Dalam contoh kami, kami menciptakan sebuah instance (' KNN ') dari kelas ' Ktetangga Sclassifer ', dengan kata lain kami telah menciptakan sebuah objek yang disebut ' KNN ' yang tahu bagaimana melakukan KNN klasifikasi setelah kami menyediakan data. Parameter ' n_neighbors ' adalah parameter tuning/Hyper parameter (k). Semua parameter lainnya diatur ke nilai default. \u200b Metode ' Fit ' digunakan untuk melatih model pada data pelatihan (X_train, y_train) dan ' memprediksi ' metode untuk melakukan pengujian pada pengujian data (X_test). Memilih nilai optimal K sangat penting, jadi kami cocok dan menguji model untuk nilai yang berbeda untuk K (dari 1 sampai 45) menggunakan untuk loop dan merekam akurasi pengujian KNN dalam variabel (Skor). #Import the KNeighborsClassifier class from sclearn from sklearn.neighbors import KNeighborsClassifier clf=KNeighborsClassifier(n_neighbors=3).fit(X_train,y_train) from sklearn.metrics import accuracy_score print(\"accuracy is \") print(accuracy_score(y_test,clf.predict(X_test))) import matplotlib.pyplot as plt accuracy_values=[] #Try running from k=1 trhough 45 and record testing accuracy k_range = range(1,45) scores = {} scores_list = [] for k in k_range: knn = KNeighborsClassifier(n_neighbors=k) knn.fit(X_train,y_train) y_pred=knn.predict(X_test) scores[k] = accuracy_score(y_test,y_pred) scores_list.append(accuracy_score(y_test,y_pred)) import numpy as np accuracy_values=np.array(accuracy_values) #plot the relationship between k and the testing accuracy plt.plot(k_range,scores_list) plt.xlabel('Value of k for KNN') plt.ylabel('Testing Accuracy') Output \u200b Jadi untuk model terakhir, kita dapat memilih nilai yang optimal K antara 3 dan 19, antara 22 dan 25 yang merupakan nilai tertinggi dari testing accuracy. Mungkin sampai disini pembahasan dari Knowladge of KNN terima kasih.....","title":"Contoh perhitungan numerik"}]}